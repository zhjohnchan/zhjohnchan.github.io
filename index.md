---
layout: homepage
---

## About Me

Hi, I am a fourth-year Ph.D. student at The Chinese University of Hong Kong, Shenzhen, where I am supervised jointly by Prof. [Xiang Wan](https://scholar.google.com/citations?user=e3_kWigAAAAJ&hl=en&oi=ao) and Prof. [Guanbin Li](http://guanbinli.com/) and also work closely with Prof. [Benyou Wang](https://wabyking.github.io/old.html). Currently, I am a visiting student at Stanford University. I received my B.Eng. degree from Sun Yat-sen University in 2019, and then became a Ph.D. student at CUHK(SZ). My research lies at the intersection of vision+language and large-scale generative models. **I am always open to collaboration. Feel free to drop me an e-mail.** :-)

<strong style="color:#e74d3c; font-weight:600">I am currently on the job market, looking for a faculty/research position on **Vision+Language**, **Large Language Models**, and their application in **medicine**. I'd appreciate a ping if you see a job I might fit.</strong>

## Research Interests

- **Vision+Language**
- **Large Language Models** 

## News
- **[Jul. 2023]** Two papers are accepted to ICCV 2023.
- **[Jun. 2023]** Lecture at CIP-SATT.
- **[May  2023]** Three papers are accepted to ACL 2023.
- **[Apr. 2023]** We are excited to release LLMZoo, including the Phoenix and Chimera models.
- **[Mar. 2023]** One paper is accepted to CVPR 2023
- **[Nov. 2022]** Two papers are accepted to AAAI 2023.
- **[Jul. 2022]** One paper is accepted to ACMMM 2022.
- **[Apr. 2022]** One paper is accepted to MICCAI 2022.
- **[Feb. 2022]** One paper is accepted to ACL 2022.

## Project

- **LLM Zoo: democratizing ChatGPT**
  <br>
  **Project Leader**
  <br>
  [[Project Website]](https://github.com/FreedomIntelligence/LLMZoo)

## Publications
### Survey Papers
- **Pre-trained Language Models in Biomedical Domain: A Systematic Survey**
  <br>
  Benyou Wang, Qianqian Xie, Jiahuan Pei, **Zhihong Chen**, Prayag Tiwari, Zhao Li, and Jie Fu
  <br>
  **ACM Computing Surveys, 2023**.
  <br>
  [[PDF](https://arxiv.org/pdf/2110.05006.pdf)]

### Research Papers
#### 2023
- **Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts**
  <br>
  **Zhihong Chen<sup>*</sup>**, Shizhe Diao<sup>*</sup>, Benyou Wang, Guanbin Li and Xiang Wan
  <br>
  **ICCV 2023**.
  <br>

- **Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation**
  <br>
  Zunnan Xu<sup>*</sup>, **Zhihong Chen<sup>*</sup>**, Yong Zhang, Yibing Song, Xiang Wan and Guanbin Li
  <br>
  **ICCV 2023**.
  <br>

- **Toward expanding the scope of radiology report summarization to multiple anatomies and modalities**
  <br>
  **Zhihong Chen<sup>*</sup>**, Maya Varma<sup>*</sup>, Xiang Wan, Curtis P. Langlotz and Jean-Benoit Delbrouck<sup>*</sup>
  <br>
  **ACL 2023**.
  <br>
  [[PDF](https://aclanthology.org/2023.acl-short.41.pdf)]

- **On the Difference of BERT-style and CLIP-style Text Encoders**
  <br>
  **Zhihong Chen<sup>*</sup>**, Guiming Hardy Chen<sup>*</sup>, Shizhe Diao, Xiang Wan and Benyou Wang
  <br>
  **Findings of ACL 2023**.
  <br>
  [[PDF](https://arxiv.org/pdf/2306.03678)] [[CODE](https://github.com/zhjohnchan/bert-clip-synesthesia)]

- **Improving Radiology Summarization with Radiograph and Anatomy Prompts**
  <br>
  Jinpeng Hu, **Zhihong Chen**, Yang Liu, Xiang Wan, and Tsung-Hui Chang.
  <br>
  **Findings of ACL 2023**.
  <br>
  [[PDF](https://arxiv.org/pdf/2210.08303)]

- **Advancing Visual Grounding with Scene Knowledge: Benchmark and Method**
  <br>
  **Zhihong Chen<sup>*</sup>**, Ruifei Zhang<sup>*</sup>, Yibin Song, Xiang Wan and Guanbin Li
  <br>
  **CVPR 2023**
  <br>
  [[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Advancing_Visual_Grounding_With_Scene_Knowledge_Benchmark_and_Method_CVPR_2023_paper.pdf)] [[CODE](https://github.com/zhjohnchan/SK-VG)]

- **EASAL: Entity-Aware Subsequence-based Active Learning for Named Entity Recognition**
  <br>
  Yang Liu, Jinpeng Hu, **Zhihong Chen**, Xiang Wan, and Tsung-Hui Chang
  <br>
  **AAAI 2023**.
  <br>
  [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/26069/25841)]

- **A Simple yet Effective Subsequence-Enhanced Approach for Cross-Domain NER**
  <br>
  Jinpeng Hu, Dandan Guo, Yang Liu, Zhuo Li, **Zhihong Chen**, Xiang Wan, and Tsung-Hui Chang
  <br>
  **AAAI 2023**.
  <br>
  [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/26515/26287)]

#### 2022
- **Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge**
  <br>
  **Zhihong Chen**, Guanbin Li and Xiang Wan
  <br>
  **ACMMM 2022**.
  <br>
  [[PDF](https://arxiv.org/pdf/2209.07118.pdf)] [[CODE](https://github.com/zhjohnchan/ARL)]

- **Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training**
  <br>
  **Zhihong Chen**, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan and Tsung-Hui Chang
  <br>
  **MICCAI 2022**.
  <br>
  [[PDF](https://arxiv.org/pdf/2209.07098.pdf)] [[CODE](https://github.com/zhjohnchan/M3AE)]

- **Graph Enhanced Contrastive Learning for Radiology Findings Summarization**
  <br>
  Jinpeng Hu, Zhuo Li, **Zhihong Chen**, Zhen Li, Xiang Wan and Tsung-Hui Chang
  <br>
  **ACL 2022**.
  <br>
  [[PDF](https://arxiv.org/pdf/2204.00203.pdf)] [[CODE](https://github.com/jinpeng01/AIG_CL)]

#### 2021
- **Cross-modal Memory Networks for Radiology Report Generation**
  <br>
  **Zhihong Chen**, Yaling Shen, Yan Song and Xiang Wan
  <br>
  **ACL 2021**.
  <br>
  [[PDF](https://arxiv.org/pdf/2204.13258.pdf)] [[CODE](https://github.com/zhjohnchan/R2GenCMN)]

- **Word Graph Guided Summarization for Radiology Findings**
  <br>
  Jinpeng Hu, Jianling Li, **Zhihong Chen**, Yaling Shen, Yan Song, Xiang Wan and Tsung-Hui Chang 
  <br>
  **Findings of ACL 2021**.
  <br>
  [[PDF](https://arxiv.org/pdf/2112.09925.pdf)] [[CODE](https://github.com/jinpeng01/WGSum)]

#### 2020
- **Generating Radiology Reports via Memory-driven Transformer**
  <br>
  **Zhihong Chen**, Yan Song, Tsung-Hui Chang and Xiang Wan.
  <br>
  **EMNLP 2020**.
  <br>
  [[PDF](https://arxiv.org/pdf/2010.16056.pdf)] [[CODE](https://github.com/zhjohnchan/R2Gen)]

#### 2019
- **Hierarchical Attention Network for Image Captioning**
  <br>
  Weixuan Wang, **Zhihong Chen** and Haifeng Hu
  <br>
  **AAAI 2019**.
  <br>
  [[PDF](https://ojs.aaai.org/index.php/AAAI/article/download/4924/4797)] <strong><i style="color:#e74d3c">Spotlight</i></strong>

## Services

- Reviewers: ACL (2021; 2022; 2023), EMNLP (2020; 2022), NAACL (2022), COLING (2020), ARR (2021; 2022; 2023).

## About the Profile Photo
The profile photo was generated when I was a year-three undergraduate student and just starting to learn about deep learning. My buddy Aobo Yu and I worked on a *sketch colorization* course project ([slides](https://github.com/zhjohnchan/zhjohnchan.github.io/tree/master/assets/files/dip_slides.pdf) at that time, haha) based on [StarGAN](https://github.com/yunjey/stargan). We drew the cartoon sketch by hand and colorized it automatically.
